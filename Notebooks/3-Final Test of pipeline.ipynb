{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "190fba74-7162-4390-8a04-84e383c080a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "383246c3-e5d9-416d-a225-d852f184f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator, ClassifierMixin\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_vocab_size=20000, max_len=None):\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.max_len = None\n",
    "        self.tokenizer = Tokenizer(num_words=self.max_vocab_size)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        print(\"Text: \", X)\n",
    "        self.tokenizer.fit_on_texts(X)\n",
    "        self.word_index = self.tokenizer.word_index\n",
    "        self.max_len = len(self.word_index)\n",
    "        self.vocab_size = len(self.word_index)\n",
    "        if self.max_len is None:\n",
    "            self.max_len = max(len(seq) for seq in self.tokenizer.texts_to_sequences(X))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        print(\"Inside tranform function\")\n",
    "        seqs = self.tokenizer.texts_to_sequences(X)\n",
    "        X_padded = pad_sequences(seqs, maxlen=self.max_len)\n",
    "        print(\"X_padded: \", X_padded)\n",
    "        return X_padded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8826e211-ac85-4b9c-8bac-50c410b5f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        print(\"Inside Keras Clasifier fit\")\n",
    "        # Next time I will do training of model here\n",
    "        return self \n",
    "\n",
    "    def label(self, predictions):\n",
    "        # ans = [\"Spam\" if pred_i[0]==1 else \"Ham\" for pred_i in predictions]\n",
    "        ans = []\n",
    "        print(\"Inside label\")\n",
    "        for pred_i in predictions:\n",
    "            print(pred_i)\n",
    "            if pred_i == 1:\n",
    "                ans.append(\"Spam\")\n",
    "            else:\n",
    "                ans.append(\"Ham\")\n",
    "                \n",
    "        return ans\n",
    "    \n",
    "    def predict(self, X):\n",
    "        print(X)\n",
    "        predictions = self.model.predict(X)\n",
    "        pred = (predictions >= 0.5).astype(int)\n",
    "        print(\"Predictions: \", predictions)\n",
    "        return self.label(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8032b8c-e873-42d0-82d7-e74c4b8ae59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = joblib.load('Preprocessing.joblib')\n",
    "model = joblib.load('spam-ham-pipe.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8009a13-0da5-4c55-8a1d-045a82dd6143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside tranform function\n",
      "X_padded:  [[   0    0    0 ...   15 2703 1647]]\n"
     ]
    }
   ],
   "source": [
    "padd = preprocess.transform(['free!!!! you have won a lottery of 2000 dollars!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77357415-6d0a-4ff7-a20a-e6cd2a3a36d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...   15 2703 1647]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step\n",
      "Predictions:  [[0.70377225]]\n",
      "Inside label\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(padd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "559dedaa-41d5-4dbb-8005-e0066e80abc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spam']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb76c434-835b-4e8b-b38b-9c1865154d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside tranform function\n",
      "X_padded:  [[ 0  0  0 ... 50 22  3]]\n",
      "[[ 0  0  0 ... 50 22  3]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Predictions:  [[0.00317349]]\n",
      "Inside label\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Ham']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.predict(preprocess.transform(['Hey this is manas bisht, How are you??']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584fa86-7c84-4635-84c7-07cce84182ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
